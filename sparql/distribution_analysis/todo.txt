Bias Assessment LP Benchmarks

Main question: What unwanted biases may influence the prediction result

- Do models that overfit on overrepresented entities perform better results than those that don't?
===============================

1. Bias in dataset

1.1 Underlying graph structure (based on Knowledge base it was sampled from)
- Are high-degree entities easier to predict? If so, how many are there? --> Distribution analysis
- Does the model need to learn only about few entities to achieve good results? --> Overrepresentation of entities in triples 
- Ratio between entities - relations
- Are certain head-predicate combos doomed to one prediction result due to overrepresented tails? vv for tails


1.2. Splitting technique
- Problem of static splitting technique, no k-cross validation
- Incosistency of proportions (Is ratio training:valid:test the same across different datasets)
- Are training and test obtained from the same uniform sample of the KG? --> Inconsistency in probing (Were the subgraphs selected randomly? If not, why bad?)

1.3. Bias in the filtering technique
- Were creators filtering for specific patterns?
- Are those filtered patterns useful for evaluating models performance in learning them (e.g. inverse relations)

1.4. Bias in test set 
- To what degree are useful patterns tested for (logical rules, including inverse relations, near duplicates, etc.)

2. Bias in evaluation metric
- Issue of not being task-agnostic (question answering vs knowledge graph completion)
- Problem of only evaluating for correct positive facts 
- Tie policy behavior (What if model applies plausibility of 1 to everything?, see Rossi)
- What percentage of entities lead to Hits@K?
- Issue of Hits@10 being to wide 
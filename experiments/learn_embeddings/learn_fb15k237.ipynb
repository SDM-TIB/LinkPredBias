{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ampligraph\n",
    "import numpy as np\n",
    "from ampligraph.datasets import load_fb15k_237\n",
    "from ampligraph.latent_features import ScoringBasedEmbeddingModel\n",
    "from ampligraph.evaluation import mrr_score, hits_at_n_score\n",
    "from ampligraph.latent_features.loss_functions import get as get_loss\n",
    "from ampligraph.latent_features.regularizers import get as get_regularizer\n",
    "from ampligraph.utils import save_model\n",
    "import tensorflow as tf\n",
    "\n",
    "# load dataset\n",
    "X = load_fb15k_237()\n",
    "\n",
    "model = ScoringBasedEmbeddingModel(k=400,\n",
    "                                   eta=30,\n",
    "                                   scoring_type='TransE')\n",
    "\n",
    "# Optimizer, loss and regularizer definition\n",
    "optim = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "loss = get_loss('multiclass_nll')\n",
    "regularizer = get_regularizer('LP', {'p': 2, 'lambda': 0.0001})\n",
    "\n",
    "# Compilation of the model\n",
    "model.compile(optimizer=optim, loss=loss, entity_relation_regularizer=regularizer)\n",
    "\n",
    "# For evaluation, we can use a filter which would be used to filter out\n",
    "# positives statements created by the corruption procedure.\n",
    "# Here we define the filter set by concatenating all the positives\n",
    "filter = {'test' : np.concatenate((X['train'], X['valid'], X['test']))}\n",
    "\n",
    "# Early Stopping callback\n",
    "checkpoint = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_{}'.format('hits10'),\n",
    "    min_delta=0,\n",
    "    patience=5,\n",
    "    verbose=1,\n",
    "    mode='max',\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Fit the model on training and validation set\n",
    "batch_count = 64\n",
    "model.fit(X['train'],\n",
    "          batch_size=int(X['train'].shape[0] / batch_count),\n",
    "          epochs=4000,                    # Number of training epochs\n",
    "          validation_freq=20,           # Epochs between successive validation\n",
    "          validation_burn_in=100,       # Epoch to start validation\n",
    "          validation_data=X['valid'],   # Validation data\n",
    "          validation_filter=filter,     # Filter positives from validation corruptions\n",
    "          callbacks=[checkpoint],       # Early stopping callback (more from tf.keras.callbacks are supported)\n",
    "          verbose=True                  # Enable stdout messages\n",
    "          )\n",
    "\n",
    "\n",
    "# Run the evaluation procedure \n",
    "ranks = model.evaluate(X['test'],\n",
    "                       use_filter=filter,\n",
    "                       corrupt_side='s,o')\n",
    "\n",
    "# Compute and print metrics:\n",
    "mrr = mrr_score(ranks)\n",
    "hits_10 = hits_at_n_score(ranks, n=10)\n",
    "print(\"MRR: %f, Hits@10: %f\" % (mrr, hits_10))\n",
    "\n",
    "# Save the model\n",
    "storage_path = \"output\"\n",
    "save_model(model, model_name_path=storage_path)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

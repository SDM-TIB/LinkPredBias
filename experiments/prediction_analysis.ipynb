{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from ampligraph.datasets import load_fb15k_237, load_wn18rr, load_fb15k, load_wn18\n",
    "from ampligraph.evaluation import mrr_score, hits_at_n_score\n",
    "from ampligraph.utils import restore_model\n",
    "from collections import defaultdict\n",
    "\n",
    "# Stores ranks for every dataset\n",
    "ranks_for_dataset = defaultdict()\n",
    "datasets = \"fb15k\", \"fb15k237\", \"wn18\", \"wn18rr\"\n",
    "for dataset in datasets:\n",
    "  X = None\n",
    "  if dataset == \"fb15k\":\n",
    "    X = load_fb15k()\n",
    "  elif dataset == \"fb15k237\":\n",
    "    X = load_fb15k_237()\n",
    "  elif dataset == \"wn18\":\n",
    "    X = load_wn18()\n",
    "  elif dataset == \"wn18rr\":\n",
    "    X = load_wn18rr()\n",
    "\n",
    "  # Retrieve trained model\n",
    "  storage_path = \"/content/drive/MyDrive/AI-LP/final/{}\".format(dataset)\n",
    "  model = restore_model(model_name_path=storage_path)\n",
    "\n",
    "  # Using filtered settings\n",
    "  filter = {'test' : np.concatenate((X['train'], X['valid'], X['test']))}\n",
    "\n",
    "  # Calculate ranks for both head and tail entities\n",
    "  ranks = model.evaluate(X['test'],\n",
    "                        use_filter=filter,\n",
    "                        corrupt_side='s,o')\n",
    "  ranks_for_dataset[dataset] = ranks\n",
    "\n",
    "  # compute and print metrics:\n",
    "  mrr = mrr_score(ranks)\n",
    "  hits_10 = hits_at_n_score(ranks, n=10)\n",
    "  print(\"Metrics for %s --- MRR: %f, Hits@10: %f\" % (dataset, mrr, hits_10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from statistics import mean\n",
    "\n",
    "datasets = \"fb15k\", \"fb15k237\", \"wn18\", \"wn18rr\"\n",
    "for dataset in datasets:\n",
    "  X = None\n",
    "  if dataset == \"fb15k\":\n",
    "    X = load_fb15k()\n",
    "  elif dataset == \"fb15k237\":\n",
    "    X = load_fb15k_237()\n",
    "  elif dataset == \"wn18\":\n",
    "    X = load_wn18()\n",
    "  elif dataset == \"wn18rr\":\n",
    "    X = load_wn18rr()\n",
    "\n",
    "  defaultTail_df = pd.read_csv(\"/content/drive/MyDrive/AI-LP/biasedPatterns/{}/defaultTail.csv\".format(dataset))\n",
    "  defaultHead_df = pd.read_csv(\"/content/drive/MyDrive/AI-LP/biasedPatterns/{}/defaultHead.csv\".format(dataset))\n",
    "  overrepresentedTail_df = pd.read_csv(\"/content/drive/MyDrive/AI-LP/biasedPatterns/{}/overrepresentedTail.csv\".format(dataset))\n",
    "  overrepresentedHead_df = pd.read_csv(\"/content/drive/MyDrive/AI-LP/biasedPatterns/{}/overrepresentedHead.csv\".format(dataset))\n",
    "  duplicate_df = pd.read_csv(\"/content/drive/MyDrive/AI-LP/biasedPatterns/{}/nearDuplicate.csv\".format(dataset))\n",
    "  inverse_df = pd.read_csv(\"/content/drive/MyDrive/AI-LP/biasedPatterns/{}/nearInverse.csv\".format(dataset))\n",
    "  symmetry_df = pd.read_csv(\"/content/drive/MyDrive/AI-LP/biasedPatterns/{}/nearSymmetry.csv\".format(dataset))\n",
    "\n",
    "  test_statements = [' '.join(x) for x in X['test']]\n",
    "  ranks = ranks_for_dataset[dataset]\n",
    "\n",
    "\n",
    "  defaultTailRelation = set((str, str))\n",
    "  defaultHeadRelation = set((str, str))\n",
    "  overrepresentedTailRelation = set((str, str))\n",
    "  overrepresentedHeadRelation = set((str, str))\n",
    "  duplicateRelations = set()\n",
    "  inverseRelations = set()\n",
    "  symmetricRelations = set()\n",
    "\n",
    "  for i, row in defaultTail_df.iterrows():\n",
    "    tail, rel = row[\"option\"], row[\"relation\"]\n",
    "    defaultTailRelation.add((tail, rel))\n",
    "  \n",
    "  for i, row in defaultHead_df.iterrows():\n",
    "    tail, rel = row[\"option\"], row[\"relation\"]\n",
    "    defaultHeadRelation.add((tail, rel))\n",
    "\n",
    "  for i, row in overrepresentedTail_df.iterrows():\n",
    "    tail, rel = row[\"tail\"], row[\"relation\"]\n",
    "    overrepresentedTailRelation.add((tail, rel))\n",
    "  \n",
    "  for i, row in overrepresentedHead_df.iterrows():\n",
    "    tail, rel = row[\"head\"], row[\"relation\"]\n",
    "    overrepresentedHeadRelation.add((tail, rel))\n",
    "\n",
    "  for i, row in duplicate_df.iterrows():\n",
    "    duplicateRelations.add(row[\"r\"])\n",
    "\n",
    "  for i, row in inverse_df.iterrows():\n",
    "    inverseRelations.add(row[\"relation\"])\n",
    "  \n",
    "  for i, row in symmetry_df.iterrows():\n",
    "    symmetricRelations.add(row[\"relation\"])\n",
    "\n",
    "  \n",
    "  for setting in \"head\", \"tail\":\n",
    "    output_frame = pd.DataFrame(columns=[\"H@K\",\"inverseAffected\", \n",
    "                                         \"duplicateAffected\",\n",
    "                                         \"symmetryAffected\",\"defaultAffected\", \n",
    "                                         \"overrepresentedAffected\",\n",
    "                                         \"unknownPredictions\", \"correctPredictions\"])\n",
    "    for tolerance in [1, 3, 5, 10]:\n",
    "      defaultAffected = 0\n",
    "      overrepresentedAffected = 0\n",
    "      inverseAffected = 0\n",
    "      duplicateAffected = 0\n",
    "      symmetryAffected = 0\n",
    "      unknown = 0\n",
    "      correct_predictions = 0\n",
    "      for i in range(len(ranks)):\n",
    "        if \"fb\" in dataset:\n",
    "          head = \"http://bias.org/entity\" + X['test'][i][0] \n",
    "          relation = \"http://bias.org/vocab\" + X['test'][i][1] \n",
    "          tail = \"http://bias.org/entity\" + X['test'][i][2] \n",
    "        else:\n",
    "          head = \"http://bias.org/entity/\" + X['test'][i][0] \n",
    "          relation = \"http://bias.org/vocab/\" + X['test'][i][1] \n",
    "          tail = \"http://bias.org/entity/\" + X['test'][i][2] \n",
    "\n",
    "        if setting == \"head\":\n",
    "          isDefaultAffected = (head, relation) in defaultHeadRelation\n",
    "          isOverrepresentedAffect = (head, relation) in overrepresentedHeadRelation\n",
    "        elif setting ==\"tail\":\n",
    "          isDefaultAffected = (tail, relation) in defaultTailRelation\n",
    "          isOverrepresentedAffect = (tail, relation) in overrepresentedTailRelation\n",
    "        \n",
    "        isInverseRelation = relation in inverseRelations\n",
    "        isDuplicateRelation = relation in duplicateRelations\n",
    "        isSymmetricRelation = relation in symmetricRelations\n",
    "        current_rank = ranks[i][1] if setting == \"tail\" else ranks[i][0]\n",
    "\n",
    "        if current_rank <= tolerance:\n",
    "          correct_predictions += 1\n",
    "          if isDefaultAffected:\n",
    "            defaultAffected += 1\n",
    "          if isOverrepresentedAffect:\n",
    "            overrepresentedAffected += 1\n",
    "          if isInverseRelation:\n",
    "            inverseAffected += 1\n",
    "          if isDuplicateRelation:\n",
    "            duplicateAffected += 1\n",
    "          if isSymmetricRelation:\n",
    "            symmetryAffected += 1\n",
    "          if (not isDefaultAffected) and (not isDuplicateRelation) and (not isInverseRelation) and (not isOverrepresentedAffect) and (not isSymmetricRelation):\n",
    "            unknown += 1\n",
    "\n",
    "      # Write results to dataframe\n",
    "      new_row = {'H@K': tolerance, \n",
    "                 'inverseAffected': inverseAffected, \n",
    "                 'duplicateAffected': duplicateAffected,\n",
    "                 'symmetryAffected': symmetryAffected, \n",
    "                 'defaultAffected': defaultAffected, \n",
    "                 'overrepresentedAffected': overrepresentedAffected,\n",
    "                 'unknownPredictions': unknown, \n",
    "                 'correctPredictions': correct_predictions }\n",
    "      output_frame.loc[len(output_frame)] = new_row\n",
    "     \n",
    "\n",
    "    output_frame.to_csv(\"output/{}_{}.csv\".format(dataset, setting), index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
